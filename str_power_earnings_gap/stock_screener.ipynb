{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-13 14:11:31.822816] INFO: Norgate Data: NorgateData package v1.0.74: Init complete\n",
      "connected to: dbmaster\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import func\n",
    "\n",
    "sys.path.append(os.path.abspath('../../fin_data'))\n",
    "from utils.date_functions import last_business_day\n",
    "from utils.helper_functions import get_test_universe_tickers\n",
    "from utils.postgresql_conn import get_session\n",
    "from utils.postgresql_tables import Company, Tickers, HistoricalPrice\n",
    "from utils.postgresql_data_query import get_effective_dates, get_company_reports_in_period\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions\n",
    "def create_universe_df(session, tickers, earnings_dict):\n",
    "    \n",
    "    company_id_mapping = session.query(Company.ticker, Company.id).filter(Company.ticker.in_(tickers)).all()\n",
    "    ticker_to_company_id = {ticker: company_id for ticker, company_id in company_id_mapping}\n",
    "    \n",
    "    ticker_id_mapping = session.query(Tickers.ticker, Tickers.id).filter(Tickers.ticker.in_(tickers)).all()\n",
    "    ticker_to_ticker_id = {ticker: ticker_id for ticker, ticker_id in ticker_id_mapping}\n",
    "\n",
    "    data = []\n",
    "    for ticker in tickers:\n",
    "        company_id = ticker_to_company_id.get(ticker)\n",
    "        ticker_id = ticker_to_ticker_id.get(ticker)\n",
    "        if company_id and company_id in earnings_dict:\n",
    "            report_date = earnings_dict[company_id]\n",
    "            data.append([ticker, company_id, ticker_id, report_date])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['ticker', 'company_id', 'ticker_id','report_date'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_price_data(session, ticker_dates_dict):\n",
    "    \"\"\"\n",
    "    Queries the historical_price table for price data for 3 days: the most recent day before, the day of, \n",
    "    and the first available day after the report_date, if available.\n",
    "    \n",
    "    Args:\n",
    "    - session: Database session object.\n",
    "    - ticker_dates_dict: Dictionary where key is ticker_id and value is the report_date.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns ['ticker_id', 'date', 'open', 'high', 'low', 'close', 'volume']\n",
    "    \"\"\"\n",
    "    \n",
    "    all_price_data = []\n",
    "    \n",
    "    for ticker_id, report_date in ticker_dates_dict.items():\n",
    "        \n",
    "        # Get the most recent trading day before the report_date\n",
    "        day_before = (session.query(HistoricalPrice.date)\n",
    "                      .filter(HistoricalPrice.ticker_id == ticker_id)\n",
    "                      .filter(HistoricalPrice.date < report_date)\n",
    "                      .order_by(HistoricalPrice.date.desc())\n",
    "                      .first())\n",
    "        \n",
    "        # Get the first trading day after the report_date (extended to handle non-immediate days)\n",
    "        day_after = (session.query(HistoricalPrice.date)\n",
    "                     .filter(HistoricalPrice.ticker_id == ticker_id)\n",
    "                     .filter(HistoricalPrice.date > report_date)\n",
    "                     .order_by(HistoricalPrice.date.asc())\n",
    "                     .first())\n",
    "        \n",
    "        # Prepare list of dates to query\n",
    "        dates_to_query = [report_date]\n",
    "        \n",
    "        # Add day_before if it exists\n",
    "        if day_before:\n",
    "            dates_to_query.insert(0, day_before[0])\n",
    "        \n",
    "        # Add day_after if it exists\n",
    "        if day_after:\n",
    "            dates_to_query.append(day_after[0])\n",
    "        \n",
    "        # Get price data for the available days\n",
    "        price_data = (session.query(HistoricalPrice.ticker_id, \n",
    "                                    HistoricalPrice.date, \n",
    "                                    HistoricalPrice.open, \n",
    "                                    HistoricalPrice.high, \n",
    "                                    HistoricalPrice.low, \n",
    "                                    HistoricalPrice.close, \n",
    "                                    HistoricalPrice.volume)\n",
    "                      .filter(HistoricalPrice.ticker_id == ticker_id)\n",
    "                      .filter(HistoricalPrice.date.in_(dates_to_query))\n",
    "                      .all())\n",
    "        \n",
    "        # Extend the results to the final list\n",
    "        all_price_data.extend(price_data)\n",
    "    \n",
    "    # Convert the result to a DataFrame\n",
    "    df_price = pd.DataFrame(all_price_data, columns=['ticker_id', 'date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    \n",
    "    return df_price\n",
    "\n",
    "def get_volume_stats(session, ticker_dates_dict, lookback=20):\n",
    "    \"\"\"\n",
    "    Queries the last 'lookback' trading days before the report date and calculates volume stats (mean and std dev).\n",
    "    \n",
    "    Args:\n",
    "    - session: Database session object.\n",
    "    - ticker_dates_dict: Dictionary where key is ticker_id and value is the report_date.\n",
    "    - lookback: Number of trading days to look back for volume stats (default is 20).\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with ticker_id, report_date, rolling_volume_mean, and rolling_volume_std.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_volume_stats = []\n",
    "\n",
    "    for ticker_id, report_date in ticker_dates_dict.items():\n",
    "        # Step 1: Query volume data for the 20 trading days before the report date\n",
    "        # Adding a buffer of 10 extra days to handle missing or non-trading days\n",
    "        volume_data = (session.query(HistoricalPrice.ticker_id,\n",
    "                                     HistoricalPrice.date,\n",
    "                                     HistoricalPrice.volume)\n",
    "                       .filter(HistoricalPrice.ticker_id == ticker_id)\n",
    "                       .filter(HistoricalPrice.date < report_date)  # Only fetch dates before the report\n",
    "                       .order_by(HistoricalPrice.date.desc())  # Most recent first\n",
    "                       .limit(lookback + 10)  # Fetch extra days to handle weekends and holidays\n",
    "                       .all())\n",
    "        \n",
    "        # Convert the result to a DataFrame\n",
    "        df_volume = pd.DataFrame(volume_data, columns=['ticker_id', 'date', 'volume'])\n",
    "        \n",
    "        # Ensure the dates are sorted in ascending order for rolling calculations\n",
    "        df_volume = df_volume.sort_values(by='date').reset_index(drop=True)\n",
    "        \n",
    "        # Step 2: Calculate rolling mean and std deviation of volume for the last 'lookback' days\n",
    "        df_volume['rolling_volume_mean'] = df_volume['volume'].rolling(window=lookback, min_periods=1).mean()\n",
    "        df_volume['rolling_volume_std'] = df_volume['volume'].rolling(window=lookback, min_periods=1).std()\n",
    "        \n",
    "        # Step 3: Get the last row's rolling statistics, as it represents the stats just before the report date\n",
    "        last_row = df_volume.iloc[-1]\n",
    "        volume_stats = {\n",
    "            'ticker_id': ticker_id,\n",
    "            'report_date': report_date,\n",
    "            'rolling_volume_mean': last_row['rolling_volume_mean'],\n",
    "            'rolling_volume_std': last_row['rolling_volume_std']\n",
    "        }\n",
    "        \n",
    "        # Append the stats for this ticker\n",
    "        all_volume_stats.append(volume_stats)\n",
    "    \n",
    "    # Convert the stats to a DataFrame\n",
    "    df_volume_stats = pd.DataFrame(all_volume_stats)\n",
    "    \n",
    "    return df_volume_stats\n",
    "\n",
    "def merge_price_data(df_universe, df_price, df_volume_stats, filter_gap=10):\n",
    "    \"\"\"\n",
    "    Merges the price data with the universe DataFrame based on ticker_id and report_date,\n",
    "    and incorporates volume stats to calculate the volume spike as a z-score.\n",
    "    \n",
    "    Args:\n",
    "    - df_universe: DataFrame containing the tickers, company_ids, ticker_ids, and report_dates.\n",
    "    - df_price: DataFrame with historical price data sorted by ticker_id and date.\n",
    "    - df_volume_stats: DataFrame with rolling volume stats (mean and std dev) from get_volume_stats.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with calculated gap, follow-through, and volume spike z-score.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the date columns are in datetime format\n",
    "    df_universe['report_date'] = pd.to_datetime(df_universe['report_date'])\n",
    "    df_price['date'] = pd.to_datetime(df_price['date'])\n",
    "    df_volume_stats['report_date'] = pd.to_datetime(df_volume_stats['report_date'])\n",
    "    \n",
    "    # Sort price data by ticker_id and date\n",
    "    df_price = df_price.sort_values(by=['ticker_id', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    # Merge price data with df_universe\n",
    "    df_merged = pd.merge(df_universe, df_price, left_on=['ticker_id', 'report_date'], right_on=['ticker_id', 'date'], how='left')\n",
    "    \n",
    "    # Shift to get the previous day's close, next day's close, and next day's volume within each ticker_id group\n",
    "    df_price['prev_close'] = df_price.groupby('ticker_id')['close'].shift(1)\n",
    "    df_price['next_close'] = df_price.groupby('ticker_id')['close'].shift(-1)\n",
    "    df_price['next_volume'] = df_price.groupby('ticker_id')['volume'].shift(-1)\n",
    "    \n",
    "    # Merge previous close and next close/volume with df_merged\n",
    "    df_merged = pd.merge(df_merged, df_price[['ticker_id', 'date', 'prev_close']], \n",
    "                         left_on=['ticker_id', 'report_date'], right_on=['ticker_id', 'date'], how='left', suffixes=('', '_prev'))\n",
    "    \n",
    "    df_merged = pd.merge(df_merged, df_price[['ticker_id', 'date', 'next_close', 'next_volume']], \n",
    "                         left_on=['ticker_id', 'report_date'], right_on=['ticker_id', 'date'], how='left', suffixes=('', '_next'))\n",
    "    \n",
    "    # Drop unnecessary duplicate columns\n",
    "    df_merged.drop(columns=['date', 'date_prev', 'date_next'], inplace=True)\n",
    "    \n",
    "    # Step 1: Merge volume statistics (rolling mean and std) with the price data\n",
    "    df_merged = pd.merge(df_merged, df_volume_stats, on=['ticker_id', 'report_date'], how='left')\n",
    "    \n",
    "    # Step 2: Calculate gap as a percentage: (open on report day - close on prior day) / close on prior day\n",
    "    df_merged['gap'] = (df_merged['open'] - df_merged['prev_close']) / df_merged['prev_close'] * 100\n",
    "    \n",
    "    # Step 3: Calculate follow-through as a percentage: (close on next day - open on report day) / open on report day\n",
    "    df_merged['followthrough'] = (df_merged['next_close'] - df_merged['open']) / df_merged['open'] * 100\n",
    "    \n",
    "    # Step 4: Calculate volume spike z-score: (next_volume - rolling mean) / rolling std\n",
    "    df_merged['volume_zscore'] = round((df_merged['next_volume'] - df_merged['rolling_volume_mean']) / df_merged['rolling_volume_std'], 2).astype(str) + ' sigma'\n",
    "\n",
    "    # Step 5: Convert 'gap' column to numeric for filtering and apply the filter\n",
    "    df_filtered = df_merged[(df_merged['gap'].abs() + df_merged['followthrough'].abs()) >= filter_gap]  # Filter by absolute gap >= 5%\n",
    "\n",
    "    # Step 6: Convert 'gap' and 'followthrough' back to strings with percentages using .loc[]\n",
    "    df_filtered.loc[:, 'gap'] = df_filtered['gap'].round(2).astype(str) + '%'\n",
    "    df_filtered.loc[:, 'followthrough'] = df_filtered['followthrough'].round(2).astype(str) + '%'\n",
    "\n",
    "    # Step 7: Drop unnecessary columns using .loc[]\n",
    "    df_filtered = df_filtered.drop(columns=['open', 'high', 'low', 'volume', 'next_volume', \n",
    "                              'rolling_volume_mean', 'rolling_volume_std']).reset_index(drop=True)\n",
    "    \n",
    "    # Step 8: Select the final columns to display\n",
    "    df_filtered = df_filtered[['ticker', 'company_id', 'report_date', 'prev_close', \n",
    "                               'close', 'next_close', 'gap', 'followthrough', 'volume_zscore']]\n",
    "    \n",
    "    return df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical range: 2024-11-12 to 2024-10-15\n"
     ]
    }
   ],
   "source": [
    "## set up parameters\n",
    "tickers = []\n",
    "reporting_currency = None #'USD'\n",
    "cols = ['Date','Open','High','Low','Close','Volume']\n",
    "path = '/Users/VadimKovshov/Dropbox/INVESTMENTS/EVALUTE/STOCKS/MODEL_OUTPUTS/POWER_EARNINGS_GAP/'\n",
    "\n",
    "w_offset = 0\n",
    "d_offset = max(1, w_offset * 7)\n",
    "end = last_business_day(offset=d_offset)\n",
    "start = last_business_day(offset=d_offset + 28)\n",
    "current_date = dt.date.today()\n",
    "print(f'Historical range: {end.strftime(\"%Y-%m-%d\")} to {start.strftime(\"%Y-%m-%d\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to: dbmaster\n",
      "Universe dates: 2024-11-08, 2024-11-01\n",
      "Universe tickers: 1760\n"
     ]
    }
   ],
   "source": [
    "# get universe dates, tickers & id's\n",
    "session = get_session()\n",
    "eff_date, pr_date = get_effective_dates(offset_0=w_offset)\n",
    "print(f'Universe dates: {eff_date.strftime(\"%Y-%m-%d\")}, {pr_date.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "for date in [eff_date, pr_date]:\n",
    "    tickers.extend(get_test_universe_tickers(session, date, currency_reporting=reporting_currency))\n",
    "tickers = list(set(tickers))\n",
    "print(f'Universe tickers: {len(tickers)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Companies reported: 1351\n"
     ]
    }
   ],
   "source": [
    "company_reports = get_company_reports_in_period(session, start_date=start, end_date=end, dimension='arq')\n",
    "df_universe = create_universe_df(session, tickers=tickers, earnings_dict=company_reports) \\\n",
    "                                .sort_values(by=['report_date','ticker'], ascending=[False, True]) \\\n",
    "                                .reset_index(drop=True)\n",
    "ticker_dates_dict = dict(zip(df_universe['ticker_id'], df_universe['report_date']))\n",
    "print(f'Companies reported: {len(df_universe)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain & merge price data with universe data, volume data and calculate the gap and follow-through\n",
    "df_price = get_price_data(session, ticker_dates_dict=ticker_dates_dict)\n",
    "df_volume_stats = get_volume_stats(session, ticker_dates_dict=ticker_dates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_price_data(df_universe=df_universe, df_price=df_price, df_volume_stats=df_volume_stats, filter_gap=10)\n",
    "df_merged.to_clipboard(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_id</th>\n",
       "      <th>report_date</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>close</th>\n",
       "      <th>next_close</th>\n",
       "      <th>gap</th>\n",
       "      <th>followthrough</th>\n",
       "      <th>volume_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKAM</td>\n",
       "      <td>3781</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>104.40</td>\n",
       "      <td>89.37</td>\n",
       "      <td>91.07</td>\n",
       "      <td>-6.22%</td>\n",
       "      <td>-6.99%</td>\n",
       "      <td>3.19 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXON</td>\n",
       "      <td>11996</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>468.75</td>\n",
       "      <td>603.18</td>\n",
       "      <td>616.14</td>\n",
       "      <td>15.2%</td>\n",
       "      <td>14.1%</td>\n",
       "      <td>7.04 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BILL</td>\n",
       "      <td>2992</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>65.90</td>\n",
       "      <td>77.31</td>\n",
       "      <td>85.89</td>\n",
       "      <td>18.71%</td>\n",
       "      <td>9.79%</td>\n",
       "      <td>4.56 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DKNG</td>\n",
       "      <td>12614</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>38.98</td>\n",
       "      <td>40.13</td>\n",
       "      <td>43.21</td>\n",
       "      <td>0.36%</td>\n",
       "      <td>10.46%</td>\n",
       "      <td>3.0 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVH</td>\n",
       "      <td>10568</td>\n",
       "      <td>2024-11-08</td>\n",
       "      <td>24.57</td>\n",
       "      <td>13.36</td>\n",
       "      <td>15.13</td>\n",
       "      <td>-41.39%</td>\n",
       "      <td>5.07%</td>\n",
       "      <td>10.08 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>GPC</td>\n",
       "      <td>11143</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>143.12</td>\n",
       "      <td>113.11</td>\n",
       "      <td>116.24</td>\n",
       "      <td>-15.85%</td>\n",
       "      <td>-3.49%</td>\n",
       "      <td>13.04 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>HRI</td>\n",
       "      <td>11024</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>169.07</td>\n",
       "      <td>198.60</td>\n",
       "      <td>209.56</td>\n",
       "      <td>2.98%</td>\n",
       "      <td>20.37%</td>\n",
       "      <td>9.54 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>MEDP</td>\n",
       "      <td>8308</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>352.92</td>\n",
       "      <td>326.54</td>\n",
       "      <td>330.07</td>\n",
       "      <td>-13.58%</td>\n",
       "      <td>8.22%</td>\n",
       "      <td>0.97 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>MMM</td>\n",
       "      <td>4964</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>134.84</td>\n",
       "      <td>131.73</td>\n",
       "      <td>127.91</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>-8.76%</td>\n",
       "      <td>5.91 sigma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>PII</td>\n",
       "      <td>12707</td>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>80.19</td>\n",
       "      <td>72.22</td>\n",
       "      <td>69.68</td>\n",
       "      <td>-0.24%</td>\n",
       "      <td>-12.9%</td>\n",
       "      <td>8.0 sigma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker  company_id report_date  prev_close   close  next_close      gap   \n",
       "0     AKAM        3781  2024-11-08      104.40   89.37       91.07   -6.22%  \\\n",
       "1     AXON       11996  2024-11-08      468.75  603.18      616.14    15.2%   \n",
       "2     BILL        2992  2024-11-08       65.90   77.31       85.89   18.71%   \n",
       "3     DKNG       12614  2024-11-08       38.98   40.13       43.21    0.36%   \n",
       "4      EVH       10568  2024-11-08       24.57   13.36       15.13  -41.39%   \n",
       "..     ...         ...         ...         ...     ...         ...      ...   \n",
       "321    GPC       11143  2024-10-22      143.12  113.11      116.24  -15.85%   \n",
       "322    HRI       11024  2024-10-22      169.07  198.60      209.56    2.98%   \n",
       "323   MEDP        8308  2024-10-22      352.92  326.54      330.07  -13.58%   \n",
       "324    MMM        4964  2024-10-22      134.84  131.73      127.91    3.97%   \n",
       "325    PII       12707  2024-10-22       80.19   72.22       69.68   -0.24%   \n",
       "\n",
       "    followthrough volume_zscore  \n",
       "0          -6.99%    3.19 sigma  \n",
       "1           14.1%    7.04 sigma  \n",
       "2           9.79%    4.56 sigma  \n",
       "3          10.46%     3.0 sigma  \n",
       "4           5.07%   10.08 sigma  \n",
       "..            ...           ...  \n",
       "321        -3.49%   13.04 sigma  \n",
       "322        20.37%    9.54 sigma  \n",
       "323         8.22%    0.97 sigma  \n",
       "324        -8.76%    5.91 sigma  \n",
       "325        -12.9%     8.0 sigma  \n",
       "\n",
       "[326 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.to_csv(f'{path}power_earnings_gap_{current_date}.csv', index=False)\n",
    "df_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
