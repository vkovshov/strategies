{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-06 23:31:30.852868] INFO: Norgate Data: NorgateData package v1.0.74: Init complete\n",
      "connected to: dbmaster\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "sys.path.append(os.path.abspath('../../fin_data'))\n",
    "from utils.postgresql_conn import get_session\n",
    "from utils.postgresql_tables import *\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from fin_statement_values_ml import main as extract_financial_data\n",
    "from utils.date_functions import time_elapsed\n",
    "from sqlalchemy import desc\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_reporting = 'USD' # or None\n",
    "model_date = date.today()\n",
    "data_date = pd.to_datetime('2024-10-04')\n",
    "use_ready_data = True # or None\n",
    "iter_range = [10000]\n",
    "data_path = '/Users/VadimKovshov/Dropbox/INVESTMENTS/EVALUTE/STOCKS/MODEL_OUTPUTS/FUNDAMENTAL_OVER_UNDER/DATA/'\n",
    "output_path = '/Users/VadimKovshov/Dropbox/INVESTMENTS/EVALUTE/STOCKS/MODEL_OUTPUTS/FUNDAMENTAL_OVER_UNDER/OUTPUT/'\n",
    "file_data_path = f'{data_path}aggregated_fin_statements_{data_date.strftime(\"%Y%m%d\")}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Extraction: Pick one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with data extraction...\n",
      "1658\n"
     ]
    }
   ],
   "source": [
    "if use_ready_data:\n",
    "    # Run this block to use one of the earlier data extractions\n",
    "    extracted_data = pd.read_csv(file_data_path)\n",
    "    print(\"Done with data extraction...\")\n",
    "    print(len(extracted_data))\n",
    "    extracted_data.head(3)\n",
    "else:\n",
    "    # Or run this block to extract new data\n",
    "    session = get_session()\n",
    "    try:\n",
    "        extracted_data = extract_financial_data(date=data_date, exclude_financial_sector=False, \n",
    "                                                currency_reporting=currency_reporting)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data extraction: {e}\")\n",
    "        extracted_data = None\n",
    "        session.rollback()\n",
    "\n",
    "    print(\"Done with data extraction...\")\n",
    "    print(f\"Tickers extracted: {len(extracted_data['ticker'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting Variables: ['cashneq', 'inventory', 'receivables', 'ppnenet', 'assets', 'payables', 'debtc', 'debtnc', 'debt', 'equity', 'retearn', 'revenue', 'cor', 'gp', 'sgna', 'rnd', 'opinc', 'intexp', 'taxexp', 'netinccmn', 'epsdil', 'dps', 'depamor', 'ncfo', 'capex', 'ncfi', 'ncff', 'fcf']\n"
     ]
    }
   ],
   "source": [
    "# Creating accounting variables list\n",
    "headers = extracted_data.columns\n",
    "headers_list = headers.tolist()\n",
    "\n",
    "relevant_headers = ['cashneq', 'inventory', 'receivables', 'ppnenet', 'assets', \n",
    "                    'payables', 'debtc', 'debtnc', 'debt', 'equity', 'retearn', \n",
    "                    'revenue', 'cor', 'gp', 'sgna', 'rnd', 'opinc', 'intexp', \n",
    "                    'taxexp', 'netinccmn', 'epsdil', 'dps', 'depamor', 'ncfo', \n",
    "                    'capex', 'ncfi', 'ncff', 'fcf']\n",
    "\n",
    "accounting_variables = [header for header in headers_list if header in relevant_headers]\n",
    "print(\"Accounting Variables:\", accounting_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions\n",
    "def estimate_fair_value_ols(data, accounting_variables):\n",
    "    X = data[accounting_variables]\n",
    "    y = data['market_cap']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_scaled, y)\n",
    "    data['fair_value_ols'] = model.predict(X_scaled)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def estimate_fair_value_ts_with_sampling(data, accounting_variables, num_samples=100000, sample_size=100):\n",
    "    X_all = data[accounting_variables]\n",
    "    y_all = data['market_cap']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_all_scaled = scaler.fit_transform(X_all)\n",
    "    \n",
    "    firms = data.index\n",
    "    predictions = {firm: [] for firm in firms}\n",
    "    \n",
    "    for _ in tqdm(range(num_samples), desc=\"Theil-Sen Sampling\"):\n",
    "        sample_indices = np.random.choice(firms, size=sample_size, replace=True)\n",
    "        X_sample = X_all_scaled[sample_indices]\n",
    "        y_sample = y_all.iloc[sample_indices]\n",
    "        \n",
    "        model = TheilSenRegressor()\n",
    "        model.fit(X_sample, y_sample)\n",
    "        \n",
    "        for firm in firms:\n",
    "            X_firm = X_all_scaled[firm].reshape(1, -1)  # Ensure it's a 2D array\n",
    "            prediction = model.predict(X_firm)[0]\n",
    "            predictions[firm].append(prediction)\n",
    "    \n",
    "    data['fair_value_ts'] = [np.median(predictions[firm]) for firm in firms]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def calculate_mispricing(data, fair_value_column):\n",
    "    # Generate the mispricing column name\n",
    "    mispricing_column = f'mispricing_{fair_value_column.split(\"_\")[-1]}'\n",
    "    \n",
    "    # Ensure fair_value_column exists in the DataFrame\n",
    "    if fair_value_column not in data.columns:\n",
    "        raise KeyError(f\"'{fair_value_column}' does not exist in the DataFrame\")\n",
    "    \n",
    "    # Calculate the mispricing column\n",
    "    data[mispricing_column] = data['market_cap'] - data[fair_value_column]\n",
    "    \n",
    "    # Initialize the mispricing percentage column with NaN\n",
    "    mispricing_pct_column = f'{mispricing_column}_pct'\n",
    "    data[mispricing_pct_column] = np.nan\n",
    "    \n",
    "    # Set mispricing to 1000% where fair value is negative\n",
    "    negative_fair_value_mask = data[fair_value_column] < 0\n",
    "    data.loc[negative_fair_value_mask, mispricing_pct_column] = 1000\n",
    "    \n",
    "    # Create a mask for non-zero and positive fair value (to avoid division by zero or negative)\n",
    "    mask = (data[mispricing_column] != 0) & ~negative_fair_value_mask\n",
    "    \n",
    "    # Perform the division only where the fair value is positive and non-zero\n",
    "    data.loc[mask, mispricing_pct_column] = (\n",
    "        (data.loc[mask, 'market_cap'] / data.loc[mask, fair_value_column] - 1) * 100\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "\n",
    "def assign_mispricing_decile(data, mispricing_pct_column):\n",
    "    data['mispricing_ts_decile'] = pd.qcut(data[mispricing_pct_column], 10, labels=False, duplicates='drop') + 1\n",
    "    return data\n",
    "\n",
    "def split_data_by_sector(data):\n",
    "    \"\"\"\n",
    "    Splits the extracted data into two datasets: one for financials and one for non-financials.\n",
    "    ompanies.\n",
    "    \"\"\"\n",
    "    # Filter financial sector\n",
    "    financial_data = data[data['sector'].str.lower() == 'financial services'].reset_index(drop=True)\n",
    "    \n",
    "    # Filter non-financial sector\n",
    "    non_financial_data = data[data['sector'].str.lower() != 'financial services'].reset_index(drop=True)\n",
    "\n",
    "    return financial_data, non_financial_data\n",
    "\n",
    "def main(data=None, acc_variables=None, random_seed=42, samples=1000, sample_size=100):\n",
    "    # Check if data is provided or create a sample dataset for testing purposes\n",
    "    if data is None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        num_firms = 1700\n",
    "        num_vars = 28\n",
    "        sectors = ['Technology', 'Healthcare', 'Financial Services', 'Consumer Cyclical', \n",
    "                   'Energy', 'Real Estate', 'Utilities', 'Industrials']  # Example sectors\n",
    "\n",
    "        # Create a sample dataset with sector information\n",
    "        data = pd.DataFrame({\n",
    "            'compid': np.arange(num_firms),\n",
    "            'ticker': [f'TKR{i}' for i in range(num_firms)],\n",
    "            'market_cap': np.random.rand(num_firms) * 1000,\n",
    "            'returns': np.random.randn(num_firms),\n",
    "            'sector': np.random.choice(sectors, num_firms)  # Assign random sectors\n",
    "        })\n",
    "        \n",
    "        for i in range(1, num_vars + 1):\n",
    "            data[f'accounting_var{i}'] = np.random.rand(num_firms) * 100\n",
    "        \n",
    "        if acc_variables is None:\n",
    "            acc_variables = [f'accounting_var{i}' for i in range(1, num_vars + 1)]\n",
    "    \n",
    "    else:\n",
    "        if acc_variables is None:\n",
    "            raise ValueError(\"acc_variables must be provided if data is provided\")\n",
    "        data = data.copy()\n",
    "\n",
    "        if 'returns' not in data.columns:\n",
    "            # Simulate returns column if it doesn't exist\n",
    "            np.random.seed(random_seed)\n",
    "            data['returns'] = np.random.randn(data.shape[0])\n",
    "\n",
    "        if 'sector' not in data.columns:\n",
    "            raise ValueError(\"Sector information is missing from the provided data\")\n",
    "\n",
    "    # Estimate fair values using OLS\n",
    "    ols_data = estimate_fair_value_ols(data.copy(), accounting_variables=acc_variables)\n",
    "\n",
    "    # Estimate fair values using Theil-Sen with sampling and time the process\n",
    "    start_time = time.time()\n",
    "    num_samples = samples  # Use a smaller number for initial timing\n",
    "    ts_data = estimate_fair_value_ts_with_sampling(data.copy(), accounting_variables=acc_variables, num_samples=num_samples, sample_size=sample_size)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    estimated_time_100000 = (elapsed_time / num_samples) * 100000\n",
    "\n",
    "    print(f\"Estimated time for 100,000 samples: {estimated_time_100000 / 60:.2f} minutes\")\n",
    "\n",
    "    # Calculate mispricing for OLS and TS\n",
    "    ts_data = calculate_mispricing(ts_data, 'fair_value_ts')\n",
    "    ols_data = calculate_mispricing(ols_data, 'fair_value_ols')\n",
    "\n",
    "    # Combine OLS and TS data into a single DataFrame, including sector info\n",
    "    combined_data = data[['compid', 'ticker', 'market_cap', 'sector']].copy()\n",
    "    \n",
    "    # Ensure 'market_cap', 'fair_value_ols', 'fair_value_ts' columns are numeric before applying formatting\n",
    "    combined_data['market_cap'] = pd.to_numeric(combined_data['market_cap'], errors='coerce').fillna(0)\n",
    "    ols_data['fair_value_ols'] = pd.to_numeric(ols_data['fair_value_ols'], errors='coerce').fillna(0)\n",
    "    ts_data['fair_value_ts'] = pd.to_numeric(ts_data['fair_value_ts'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Format values as strings with commas\n",
    "    combined_data['market_cap'] = combined_data['market_cap'].apply(lambda x: f\"{x:,.0f}\")\n",
    "    combined_data['fair_value_ols'] = ols_data['fair_value_ols'].apply(lambda x: f\"{x:,.0f}\")\n",
    "    combined_data['fair_value_ts'] = ts_data['fair_value_ts'].apply(lambda x: f\"{x:,.0f}\")\n",
    "\n",
    "    # Ensure 'mispricing_ols_pct' and 'mispricing_ts_pct' columns are numeric and round them\n",
    "    ols_data['mispricing_ols_pct'] = pd.to_numeric(ols_data['mispricing_ols_pct'], errors='coerce').fillna(0)\n",
    "    ts_data['mispricing_ts_pct'] = pd.to_numeric(ts_data['mispricing_ts_pct'], errors='coerce').fillna(0)\n",
    "\n",
    "    # Now round the numeric columns\n",
    "    combined_data['mispricing_ols_pct'] = ols_data['mispricing_ols_pct'].round(2)\n",
    "    combined_data['mispricing_ts_pct'] = ts_data['mispricing_ts_pct'].round(2)\n",
    "\n",
    "    # Calculate the average mispricing percentage (optional)\n",
    "    # combined_data['mispricing_avg_pct'] = ((combined_data['mispricing_ols_pct'] + combined_data['mispricing_ts_pct']) / 2).round(2)\n",
    "\n",
    "    # Assign mispricing deciles based on the ts mispricing percentage\n",
    "    combined_data = assign_mispricing_decile(combined_data, 'mispricing_ts_pct')\n",
    "\n",
    "    # Sort the DataFrame by mispricing decile in descending order\n",
    "    combined_data = combined_data.sort_values(by='mispricing_ts_decile', ascending=False)\n",
    "\n",
    "    print(combined_data.head())\n",
    "\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into financials and non-financials\n",
    "financial_data, non_financial_data = split_data_by_sector(data=extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process financials\n",
    "for n in iter_range:\n",
    "    combined_data = main(data=financial_data, acc_variables=accounting_variables, random_seed=42, samples=n, sample_size=20)\n",
    "    result_file_path = f'{output_path}ols_ts_mispricing_{data_date.strftime(\"%Y%m%d\")}_{n}_financials_{currency_reporting}.csv'\n",
    "    combined_data.to_csv(result_file_path, index=False)\n",
    "    print(f\"Saved result to {result_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Theil-Sen Sampling: 100%|██████████| 10000/10000 [3:45:36<00:00,  1.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated time for 100,000 samples: 2256.39 minutes\n",
      "       compid ticker market_cap             sector fair_value_ols   \n",
      "611      7139    HHH      3,844        Real Estate            825  \\\n",
      "1047      846   ELAN      7,247         Healthcare        -20,237   \n",
      "162     14033    NVR     29,283  Consumer Cyclical         48,682   \n",
      "164   2638936    BHP    153,591    Basic Materials         32,862   \n",
      "1328     7492    VRT     39,466        Industrials         35,994   \n",
      "\n",
      "     fair_value_ts  mispricing_ols_pct  mispricing_ts_pct   \n",
      "611         -2,150              366.12            1000.00  \\\n",
      "1047         3,294             1000.00             120.01   \n",
      "162        -48,354              -39.85            1000.00   \n",
      "164         26,863              367.39             471.76   \n",
      "1328        13,918                9.64             183.56   \n",
      "\n",
      "      mispricing_ts_decile  \n",
      "611                     10  \n",
      "1047                    10  \n",
      "162                     10  \n",
      "164                     10  \n",
      "1328                    10  \n",
      "Saved result to /Users/VadimKovshov/Dropbox/INVESTMENTS/EVALUTE/STOCKS/MODEL_OUTPUTS/FUNDAMENTAL_OVER_UNDER/OUTPUT/ols_ts_mispricing_20241004_10000_non_financials_USD.csv\n"
     ]
    }
   ],
   "source": [
    "# Process non-financials\n",
    "for n in iter_range:\n",
    "    combined_data = main(data=non_financial_data, acc_variables=accounting_variables, random_seed=42, samples=n, sample_size=100)\n",
    "    result_file_path = f'{output_path}ols_ts_mispricing_{data_date.strftime(\"%Y%m%d\")}_{n}_non_financials_{currency_reporting}.csv'\n",
    "    combined_data.to_csv(result_file_path, index=False)\n",
    "    print(f\"Saved result to {result_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data.to_clipboard()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
